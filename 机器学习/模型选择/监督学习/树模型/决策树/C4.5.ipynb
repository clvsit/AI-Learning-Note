{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_iris()\n",
    "x = dataset.data\n",
    "y = dataset.target\n",
    "features = dataset.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, value, type='decision'):\n",
    "        self.value = value    \n",
    "        self.type = type\n",
    "        self.children = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_shannon_ent(data, labels):\n",
    "    data_count = float(data.shape[0])\n",
    "    features = data.shape[1]\n",
    "    # 统计每个分类的个数\n",
    "    labels_count = np.array([labels[labels == label].size for label in set(labels)])\n",
    "    # 计算数据集的信息熵\n",
    "    base_ent = -np.sum((labels_count / data_count) * np.log2(labels_count / data_count))\n",
    "    # 存放各种特征值信息增益比\n",
    "    gain_list = []\n",
    "    \n",
    "    # 计算每个特征划分后的数据集的信息熵\n",
    "    for feature in range(0, features):\n",
    "        # 获取特征对应的数据\n",
    "        feature_data = data[:, feature]\n",
    "        # 获取特征信息，以特征值为 key，特征值的数目为 value\n",
    "        feature_info = {feature: feature_data[feature_data == feature].size for feature in set(feature_data)}\n",
    "        feature_shannonEnt, IV = 0, 0\n",
    "        # 获取每个特征值的分类信息并计算条件信息熵\n",
    "        for feature_value in feature_info:\n",
    "            # 当前特征值的数目\n",
    "            feature_count = float(feature_info[feature_value])\n",
    "            label_data = labels[feature_data == feature_value]\n",
    "            labels_feature = np.array([label_data[label_data == label].size for label in set(label_data)])\n",
    "            # 计算每个分类的概率\n",
    "            p_label = labels_feature / feature_count\n",
    "            feature_shannonEnt += (feature_count / data_count) * np.sum(-p_label * np.log2(p_label))\n",
    "            IV += (feature_count / data_count) * np.log2(feature_count / data_count)\n",
    "        gain_list.append((base_ent - feature_shannonEnt) / IV)\n",
    "    gain_list = np.array(gain_list)\n",
    "    return np.argmax(gain_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data, labels, feature, value):\n",
    "    \"\"\"\n",
    "    :param data:    数据集 ndarray\n",
    "    :param labels:  标签列表 ndarray\n",
    "    :param feature: 特征 \n",
    "    :param value:   特征值\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    feature_data = data[:, feature]\n",
    "    select_rows = feature_data == value\n",
    "    return (np.delete(data[select_rows], feature, axis=1), labels[select_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_label(labels):\n",
    "    return sorted([(label, len(labels[label == label])) for label in set(labels)])[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(data, labels, features):\n",
    "    # 判断：特征集是否存在，如果不存在，则当前结点作为叶结点\n",
    "    if len(features) == 0:\n",
    "        return Node(voting_label(labels))\n",
    "    # 判断：标签集，若标签只有一种，则当前结点作为叶结点\n",
    "    if len(set(labels)) == 1:\n",
    "        return Node(labels[0])\n",
    "    # 获取最优特征的下标\n",
    "    best_feature_index = calc_shannon_ent(data, labels)\n",
    "    best_feature = features[best_feature_index]    \n",
    "    # 创建结点\n",
    "    node = Node(best_feature)\n",
    "    # 将已划分的特征从特征集中移除\n",
    "    features = np.delete(features, best_feature_index)\n",
    "    # 根据最优特征划分数据集\n",
    "    best_feature_data = data[:, best_feature_index]\n",
    "    best_feature_info = {feature: best_feature_data[best_feature_data == feature].size for feature in set(best_feature_data)}\n",
    "    for feature_value in best_feature_info:\n",
    "        split_data, split_labels = split_dataset(data, labels, best_feature_index, feature_value)\n",
    "        node.children[feature_value] = create_tree(split_data, split_labels, features)\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = create_tree(x, y, list(range(x.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2.9: <__main__.Node at 0x289787af438>,\n",
       " 3.0: <__main__.Node at 0x289787af9b0>,\n",
       " 3.5: <__main__.Node at 0x289787af780>,\n",
       " 3.2: <__main__.Node at 0x289787afcc0>,\n",
       " 3.6: <__main__.Node at 0x289787aff98>,\n",
       " 3.1: <__main__.Node at 0x289787af860>,\n",
       " 3.9: <__main__.Node at 0x289787e7240>,\n",
       " 3.4: <__main__.Node at 0x289787e7278>,\n",
       " 3.7: <__main__.Node at 0x289787e74a8>,\n",
       " 4.0: <__main__.Node at 0x289787e74e0>,\n",
       " 4.4: <__main__.Node at 0x289787e7518>,\n",
       " 4.1: <__main__.Node at 0x289787e7550>,\n",
       " 2.0: <__main__.Node at 0x289787e7588>,\n",
       " 2.5: <__main__.Node at 0x289787e75c0>,\n",
       " 2.6: <__main__.Node at 0x289787e77f0>,\n",
       " 2.3: <__main__.Node at 0x289787e7940>,\n",
       " 2.8: <__main__.Node at 0x289787e7a58>,\n",
       " 2.7: <__main__.Node at 0x289787e7d68>,\n",
       " 2.2: <__main__.Node at 0x289787e7f98>,\n",
       " 3.8: <__main__.Node at 0x289787eb0f0>,\n",
       " 3.3: <__main__.Node at 0x289787eb278>,\n",
       " 4.2: <__main__.Node at 0x289787eb400>,\n",
       " 2.4: <__main__.Node at 0x289787eb438>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.children[2.9].value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
